% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predictor.R
\name{predictor_sl}
\alias{predictor_sl}
\title{Instantiate a learner}
\usage{
predictor_sl(
  learners,
  info = NULL,
  nfolds = 5L,
  meta.learner = metalearner_nnls,
  model.score = mse,
  learner.args = NULL,
  ...
)
}
\arguments{
\item{learners}{(list) List of \link{learner} objects (i.e. \link{predictor_glm})}

\item{info}{(character) Optional information to describe the instantiated
\link{ml_model} object.}

\item{nfolds}{(integer) Number of folds to use in cross-validation to
estimate the ensemble weights.}

\item{meta.learner}{(function) Algorithm to learn the ensemble
weights (default non-negative least squares). Must be a function of the
response (nx1 vector), \code{y}, and the predictions (nxp matrix), \code{pred}, with
p being the number of learners.}

\item{model.score}{(function) Model scoring method (see \link{learner})}

\item{learner.args}{(list) Additional arguments to
\link[=ml_model]{ml_model$new()}.}

\item{...}{Additional arguments to \link{superlearner}}
}
\value{
\link{ml_model} object.
}
\description{
\link{learner} generator function for \link{superlearner}
}
\examples{
sim1 <- function(n = 5e2) {
   x1 <- rnorm(n, sd = 2)
   x2 <- rnorm(n)
   y <- x1 + cos(x1) + rnorm(n, sd = 0.5**.5)
   data.frame(y, x1, x2)
}
d <- sim1()

m <- list(
  "mean" = predictor_glm(y ~ 1),
  "glm" = predictor_glm(y ~ x1 + x2),
  "iso" = predictor_isoreg(y ~ x1)
)

s <- predictor_sl(m, nfolds = 10)
s$estimate(d)
pr <- s$predict(d)
if (interactive()) {
    plot(y ~ x1, data = d)
    points(d$x1, pr, col = 2, cex = 0.5)
    lines(cos(x1) + x1 ~ x1, data = d[order(d$x1), ],
          lwd = 4, col = lava::Col("darkblue", 0.3))
}
print(s)
# weights(s)
# score(s)

cvres <- summary(s, data = d, nfolds = 3, rep = 2)
cvres
# coef(cvres)
# score(cvres)
# TODO: example showing how to extract weights
}
